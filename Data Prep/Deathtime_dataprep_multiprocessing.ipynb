{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File C:\\Users\\cchak\\Desktop\\Data_ECML\\VDI Traces\\selected_few\\2016031115-LUN2.csv_expanded_local.csv\n",
      "Min LBA in the dataset : 135368704\n",
      "Max LBA in the dataset : 5335731031071\n",
      "Number of IO Accesses : 5696823\n",
      "Number of unique LBAs :  2632402\n"
     ]
    }
   ],
   "source": [
    "# Load the input trace\n",
    "# Parallelize the job based on process id\n",
    "# Combine results\n",
    "\n",
    "# Loading required libraries\n",
    "import csv\n",
    "import sys\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import itertools\n",
    "import numpy as np\n",
    "import copy\n",
    "import math\n",
    "import time\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "# Loading trace\n",
    "path = r'C:\\Users\\cchak\\Desktop\\Data_ECML\\VDI Traces\\selected_few'\n",
    "all_files = glob.glob(os.path.join(path, \"2016031115-LUN2.csv_expanded_local.csv\"))\n",
    "\n",
    "f = all_files[0]  # Change the file name as required\n",
    "print(\"File \" + str(f))\n",
    "\n",
    "cols= ['Timestamp','Response','IOType','LUN','Offset']\n",
    "df = pd.read_csv(f,engine='python',skiprows =1,header=None,na_values=['-1'], index_col=False)\n",
    "df.columns = cols\n",
    "\n",
    "lba_list = df['Offset'].tolist()\n",
    "print(\"Min LBA in the dataset :\", min(lba_list))\n",
    "print(\"Max LBA in the dataset :\", max(lba_list))\n",
    "print(\"Number of IO Accesses :\",len(df))\n",
    "print(\"Number of unique LBAs : \",len(Counter(lba_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "from multiprocessing import Process,Queue\n",
    "\n",
    "\n",
    "def dataprep(lba_list,size_list):\n",
    "    num_processes = 1\n",
    "    processes = []\n",
    "    queue = mp.Queue()\n",
    "    results = np.ndarray(num_processes)    \n",
    "    f = all_files[0]\n",
    "    \n",
    "    for i in range(num_processes):\n",
    "        # Generate a sub-list and pass it to the multiprocessing function\n",
    "        index_start =  int((len(lba_list)/num_processes) * i)\n",
    "        index_end =  int((len(lba_list)/num_processes)) * (i+ 1) \n",
    "        arguments = lba_list,index_start,index_end, i, queue\n",
    "        p = Process(target = dataprep_multiprocessing, args = arguments)\n",
    "        p.daemon = True\n",
    "        processes.append(p)\n",
    "        processes[i].start()\n",
    "        \n",
    "    for i in range(num_processes):\n",
    "        processes[i].join()\n",
    "        \n",
    "    for i in range(num_processes):\n",
    "        results[i] = queue.get()\n",
    "        \n",
    "\n",
    "def dataprep_multiprocessing(new_lba_list,index_start,index_end, i, queue):\n",
    "    print('Process  Started:', i)\n",
    "    lba_list = []\n",
    "    death_time_list = []\n",
    "    line_counter = 0\n",
    "    counter = index_start - 1\n",
    "    print(\"Starting...\")\n",
    "    while(counter < index_end - 1):\n",
    "        counter = counter + 1\n",
    "        line_counter = line_counter + 1\n",
    "        lba = new_lba_list[counter]\n",
    "        \n",
    "        if(line_counter > 5000 and line_counter%5000 == 0):\n",
    "          print(\"Process  :\",i)\n",
    "          print(\"Counter reached  :\",line_counter)\n",
    "          print(\"Remaining  :\",index_end - counter)\n",
    "          \n",
    "          new_time_list = df[index_start:counter]['Timestamp'].tolist()\n",
    "          new_response_list = df[index_start:counter]['Response'].tolist()\n",
    "          new_lun_list = df[index_start:counter]['LUN'].tolist()\n",
    "          new_io_list = df[index_start:counter]['IOType'].tolist()\n",
    "\n",
    "          df_out = pd.DataFrame(columns = ['lba','timestamp','response','io','size','lun','death_time'])\n",
    "          df_out['lba'] = lba_list\n",
    "          df_out['death_time'] = death_time_list\n",
    "          df_out['timestamp'] = new_time_list\n",
    "          df_out['response'] = new_response_list\n",
    "          df_out['io'] = new_io_list\n",
    "          df_out['lun'] = new_lun_list\n",
    "\n",
    "          df_out.to_csv(f +str(i) +\"_deathtime_added.csv\",index=False)\n",
    "          print(\"File Written.. Still incomplete!!\")\n",
    "\n",
    "\n",
    "\n",
    "        if(new_lba_list[(counter+1):].count(lba) == 0):\n",
    "            death_time_list.append(-1)\n",
    "            lba_list.append(lba)\n",
    "        else:\n",
    "            next_lba_counter = counter + 1 \n",
    "            next_lba = new_lba_list[next_lba_counter]\n",
    "            death_counter = 1\n",
    "            while(next_lba != lba and next_lba_counter < index_end - 1):\n",
    "                next_lba_counter = next_lba_counter + 1\n",
    "                next_lba = new_lba_list[next_lba_counter]\n",
    "                death_counter = death_counter + 1\n",
    "\n",
    "            if (next_lba_counter >= len(new_lba_list) - 2):\n",
    "                death_time_list.append(-1)\n",
    "                lba_list.append(lba)\n",
    "            else:\n",
    "                death_time_list.append(death_counter)\n",
    "                lba_list.append(lba)\n",
    "    \n",
    "      \n",
    "    new_time_list = df[index_start:index_end]['Timestamp'].tolist()\n",
    "    new_response_list = df[index_start:index_end]['Response'].tolist()\n",
    "    new_lun_list = df[index_start:index_end]['LUN'].tolist()\n",
    "    new_io_list = df[index_start:index_end]['IOType'].tolist()\n",
    "    new_size_list = df[index_start:index_end]['Size'].tolist()\n",
    "    df_out = pd.DataFrame(columns = ['lba','timestamp','response','size','io','lun','death_time'])\n",
    "    df_out['lba'] = lba_list\n",
    "    df_out['death_time'] = new_size_list\n",
    "    df_out['size'] = death_time_list\n",
    "    df_out['timestamp'] = new_time_list\n",
    "    df_out['response'] = new_response_list\n",
    "    df_out['io'] = new_io_list\n",
    "    df_out['lun'] = new_lun_list\n",
    "\n",
    "    df_out.to_csv(f +str(i) +\"_deathtime_added.csv\",index=False)\n",
    "    print(\"File Written.. Done!!\")\n",
    "    queue.put(0)\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lba_list = df['Offset'].tolist()\n",
    "size_list = df['Offset'].tolist()\n",
    "num_processes = 1\n",
    "k = len(lba_list)%num_processes\n",
    "lba_list = (lba_list[:-k])\n",
    "size = (size_list[:-k])\n",
    "print(len(lba_list))\n",
    "print(len(lba_list) % num_processes)\n",
    "dataprep(lba_list,size_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
