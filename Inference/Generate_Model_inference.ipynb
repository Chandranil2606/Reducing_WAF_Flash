{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "# Load testing data\n",
    "# Model predict\n",
    "# Compute Inference time\n",
    "\n",
    "import csv\n",
    "import sys\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import itertools\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive',force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/content/drive/My Drive/AmericanPics/Test_traces/'\n",
    "all_files = glob.glob(os.path.join(path, \"testing_ssdtrace_expanded_last_50.csv\"))\n",
    "f = all_files[0]  # Change the file name as required\n",
    "print(\"File \" + str(f))\n",
    "df = pd.read_csv(f,skiprows =2,header=None,na_values=['-1'], index_col=False,low_memory=False)\n",
    "cols = ['IO','device_major','device_minor','cpu_id','timestamp','io_sequence','process_id','default_action','lba','unknown','IO_size','deathtime']\n",
    "df.columns = cols\n",
    "lba_list = df['lba'].tolist()\n",
    "deathtime_list = df['deathtime'].tolist()\n",
    "print(\"Min LBA in the dataset :\", min(lba_list))\n",
    "print(\"Max LBA in the dataset :\", max(lba_list))\n",
    "print(\"Number of IO Accesses :\",len(df))\n",
    "print(\"Number of unique LBAs : \",len(Counter(lba_list)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split to train, validate and test\n",
    "# Finding the value 75th percentile of TimeStamp\n",
    "import math\n",
    "\n",
    "training_pt_1 = math.floor((len(df)*0.75)) \n",
    "\n",
    "lba_train =df[:training_pt_1]['lba_norm'].tolist()\n",
    "lba_test = df[training_pt_1+1:]['lba_norm'].tolist()\n",
    "\n",
    "response_norm_train = df[:training_pt_1]['response_norm'].tolist()\n",
    "response_norm_test = df[training_pt_1+1:]['response_norm'].tolist()\n",
    "\n",
    "death_time_norm_train = df[:training_pt_1]['deathtime_norm'].tolist()\n",
    "death_time_norm_test = df[training_pt_1+1:]['deathtime_norm'].tolist()\n",
    "\n",
    "lba_low_train = df[:training_pt_1]['lba_low_norm'].tolist()\n",
    "lba_low_test = df[training_pt_1+1:]['lba_low_norm'].tolist()\n",
    "\n",
    "lba_high_train = df[:training_pt_1]['lba_high_norm'].tolist()\n",
    "lba_high_test =  df[training_pt_1+1:]['lba_high_norm'].tolist()\n",
    "\n",
    "size_norm_train = df[:training_pt_1]['IO_size'].tolist()\n",
    "size_norm_test = df[training_pt_1+1:]['IO_size'].tolist()\n",
    "\n",
    "output_train = df[:training_pt_1]['Output_Class'].tolist()\n",
    "output_test = df[training_pt_1+1:]['Output_Class'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lba_train= np.array(lba_train).reshape(-1,1)\n",
    "lba_test= np.array(lba_test).reshape(-1,1)\n",
    "\n",
    "response_norm_train = np.array(response_norm_train).reshape(-1,1)\n",
    "response_norm_test = np.array(response_norm_test).reshape(-1,1)\n",
    "\n",
    "death_time_norm_train= np.array(death_time_norm_train).reshape(-1,1)\n",
    "death_time_norm_test= np.array(death_time_norm_test).reshape(-1,1)\n",
    "\n",
    "lba_low_train= np.array(lba_low_train).reshape(-1,1)\n",
    "lba_low_test= np.array(lba_low_test).reshape(-1,1)\n",
    "\n",
    "lba_high_train= np.array(lba_high_train).reshape(-1,1)\n",
    "lba_high_test= np.array(lba_high_test).reshape(-1,1)\n",
    "\n",
    "size_train= np.array(lba_low_train).reshape(-1,1)\n",
    "size_test= np.array(lba_low_test).reshape(-1,1)\n",
    "\n",
    "output_train= np.array(output_train).reshape(-1,1)\n",
    "output_test= np.array(output_test).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset2(dataset, window_size):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset) - 2 * window_size):\n",
    "        a = dataset[i:(i + window_size), 0]\n",
    "        #print(a)\n",
    "        dataX.append(a)\n",
    "        b = dataset[(i + window_size):(i + 2* window_size), 0]\n",
    "        #print(b)\n",
    "        dataY.append(b)\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "lstm_num_timesteps = 32\n",
    "    \n",
    "X_train_lba, y_train_lba = create_dataset2(lba_train, lstm_num_timesteps)\n",
    "X_test_lba, y_test_lba = create_dataset2(lba_test, lstm_num_timesteps)\n",
    "\n",
    "X_train_response, y_train_response = create_dataset2(response_norm_train, lstm_num_timesteps)\n",
    "X_test_response, y_test_response = create_dataset2(response_norm_test, lstm_num_timesteps)\n",
    "\n",
    "X_train_deathtime, y_train_deathtime = create_dataset2(death_time_norm_train, lstm_num_timesteps)\n",
    "X_test_deathtime, y_test_deathtime = create_dataset2(death_time_norm_test, lstm_num_timesteps)\n",
    "\n",
    "X_train_lba_low, y_train_lba_low = create_dataset2(lba_low_train, lstm_num_timesteps)\n",
    "X_test_lba_low, y_test_lba_low = create_dataset2(lba_low_test, lstm_num_timesteps)\n",
    "\n",
    "X_train_lba_high, y_train_lba_high = create_dataset2(lba_high_train, lstm_num_timesteps)\n",
    "X_test_lba_high, y_test_lba_high = create_dataset2(lba_high_test, lstm_num_timesteps)\n",
    "\n",
    "X_size, y_train_size = create_dataset2(size_train, lstm_num_timesteps)\n",
    "X_size, y_test_size = create_dataset2(size_test, lstm_num_timesteps)\n",
    "\n",
    "X_train_output, y_train_output = create_dataset2(output_train, lstm_num_timesteps)\n",
    "X_test_output, y_test_output = create_dataset2(output_test, lstm_num_timesteps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "# Load model\n",
    "# Generate inference in batch of 64\n",
    "# Save predictions\n",
    "# Save time for predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
