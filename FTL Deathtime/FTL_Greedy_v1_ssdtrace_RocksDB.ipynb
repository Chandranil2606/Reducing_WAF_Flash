{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File /Users/chandranilchakraborttii/Documents/GC_pred/data/ssdtrace-01_dataprep_complete.csv_deathtime_added_Heiner.csv\n",
      "Min LBA in the dataset : 0\n",
      "Max LBA in the dataset : 998900152\n",
      "Number of unique LBAs in the data : 179168\n",
      "Number of IO Accesses : 1062003\n"
     ]
    }
   ],
   "source": [
    "# Loading required libraries\n",
    "import csv\n",
    "import sys\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import itertools\n",
    "import numpy as np\n",
    "import copy\n",
    "import math\n",
    "import time\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "# Loading trace : Needs to expanded into 4K chunks\n",
    "path = r'/Users/chandranilchakraborttii/Documents/GC_pred/data'\n",
    "all_files = glob.glob(os.path.join(path, \"ssdtrace-01_dataprep_complete.csv_deathtime_added_Heiner.csv\"))\n",
    "\n",
    "f = all_files[0]  # Change the file name as required\n",
    "print(\"File \" + str(f))\n",
    "cols = ['io','LBA','deathtime']\n",
    "df = pd.read_csv(f,engine='python',skiprows =1,header=None,na_values=['-1'], index_col=False)\n",
    "df.columns = cols\n",
    "df['deathtime'] = df['deathtime'].replace(np.NaN, -1)\n",
    "lba_list = df['LBA'].tolist()\n",
    "print(\"Min LBA in the dataset :\", min(lba_list))\n",
    "print(\"Max LBA in the dataset :\", max(lba_list))\n",
    "print(\"Number of unique LBAs in the data :\",len(Counter(df['LBA'])))\n",
    "print(\"Number of IO Accesses :\",len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSD Capacity (Available in GB) : 0.6834716796875\n",
      "SSD Capacity (Total in GB)     : 0.820166015625\n"
     ]
    }
   ],
   "source": [
    "#SSD specifications\n",
    "num_page_addresses = len(Counter(df['LBA']))\n",
    "page_size = 4096\n",
    "page_per_block = 64    \n",
    "GB = 1024*1024*1024\n",
    "SSD_size = num_page_addresses*page_size\n",
    "# SSD_size_GB_normal = round_decimals_up(SSD_size/GB,1)\n",
    "SSD_size_GB_normal = SSD_size/GB\n",
    "over_provisioning_ratio = 0.2\n",
    "LOG_PAGE_PER_BLOCK = int(math.log(page_per_block,2))\n",
    "# SSD_size_full = round_decimals_up((1 + over_provisioning_ratio)*SSD_size_GB_normal,1)\n",
    "SSD_size_full = (1 + over_provisioning_ratio)*SSD_size_GB_normal\n",
    "print(\"SSD Capacity (Available in GB) :\",SSD_size_GB_normal)\n",
    "print(\"SSD Capacity (Total in GB)     :\",SSD_size_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING...! Not enough blocks. Need to increase SSD Size\n"
     ]
    }
   ],
   "source": [
    "GB = 1024*1024*1024\n",
    "ssd_capacity = SSD_size_full *GB\n",
    "page_addresses = []\n",
    "block_addresses = []\n",
    "block_placement = 0\n",
    "start_counter = -1\n",
    "block_addresses.append(0)\n",
    "\n",
    "while(start_counter < (ssd_capacity/page_size) - page_size):\n",
    "    start_counter = start_counter + 1\n",
    "    page_addresses.append(int(start_counter))\n",
    "    if(block_placement >= page_per_block):\n",
    "        block_addresses.append(int(start_counter))\n",
    "        block_placement = 0\n",
    "\n",
    "    block_placement = block_placement + 1\n",
    "\n",
    "free_list_block = copy.deepcopy(block_addresses)\n",
    "free_list_page = copy.deepcopy(page_addresses)\n",
    "\n",
    "# Defining block_structure\n",
    "valid_bitmap = []\n",
    "write_ptr=0\n",
    "invalid_pages=0\n",
    "block_struct = {}\n",
    "\n",
    "for x in free_list_block:\n",
    "    start_lba = x\n",
    "    valid_bitmap = []\n",
    "    for x in range(page_per_block):\n",
    "        valid_bitmap.append(False)\n",
    "    segment = [start_lba,invalid_pages,valid_bitmap,write_ptr]\n",
    "    block_struct[start_lba]=segment\n",
    "    \n",
    "\n",
    "if(len(page_addresses)*0.75 < len(Counter(df['LBA']))):\n",
    "    print(\"WARNING...! Not enough blocks. Need to increase SSD Size\")\n",
    "else:\n",
    "    print(\"Looks good.Go ahead!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invalidate_lba(lba):\n",
    "    prev = L2P[lba]\n",
    "    prev_block = (prev >> LOG_PAGE_PER_BLOCK)*page_per_block\n",
    "    prev_page = prev % page_per_block\n",
    "    block_details = block_struct[prev_block]                                 # Getting block details\n",
    "    block_struct[prev_block][2][prev_page] = False                           # Setting bitmap to False\n",
    "    block_struct[prev_block][1] = block_struct[cur_block][2].count(True)     # Setting invalid pages\n",
    "    L2P.pop(lba)\n",
    "    \n",
    "\n",
    "def map_lba(lba,cur_block):\n",
    "    phys_addr = block_struct[cur_block][0] + block_struct[cur_block][3]\n",
    "    L2P[lba] = phys_addr\n",
    "    P2L[phys_addr] = lba   \n",
    "    block_struct[cur_block][2][block_struct[cur_block][3]] =  True               # Setting Bitmap\n",
    "    block_struct[cur_block][1] =  block_struct[cur_block][2].count(True)         # Setting invalid pages\n",
    "    block_struct[cur_block][3] = block_struct[cur_block][3] + 1                  # Increasing Write pointer\n",
    "    total_writes[0] = total_writes[0] + 1\n",
    "    \n",
    "def check_GC (cur_block, in_gc):\n",
    "    if (block_struct[cur_block][3] < page_per_block):\n",
    "        return cur_block\n",
    "    else:\n",
    "        closed_blocks.append(cur_block)\n",
    "        if(len(free_list_block) <= 0):\n",
    "            print(\"FAIL WHILE DOING GC, RAN OUT OF BLOCKS\") \n",
    "        elif (len(free_list_block) <= GC_THRESHOLD):\n",
    "            if(in_gc != True):\n",
    "                if(block_struct[cur_block][3] >= page_per_block):\n",
    "                    cur_block = free_list_block.pop(0)\n",
    "                in_gc = do_greedy_gc(cur_block,in_gc)\n",
    "        if(block_struct[cur_block][3] == (page_per_block)):\n",
    "            cur_block = free_list_block.pop(0)\n",
    "        return cur_block\n",
    "\n",
    "\n",
    "def do_greedy_gc(cur_block,in_gc):\n",
    "    in_gc = True\n",
    "    gc_writes = 0\n",
    "    min_val = float('inf')  \n",
    "    for x in closed_blocks:               \n",
    "        if (block_struct[x][1] < min_val):\n",
    "            min_val = block_struct[x][1]\n",
    "            gc_blk = x\n",
    "\n",
    "    \n",
    "    #found the block with minimal valid pages, move all valid pages\n",
    "    for pg in range(page_per_block):\n",
    "        #figure out the logical addresses for all phys pages in the gc block\n",
    "        phys_addr = block_struct[gc_blk][0] + pg\n",
    "        gc_lba = P2L[phys_addr]\n",
    "        \n",
    "        # Checking for valid bitmap\n",
    "        prev_block = (phys_addr >> LOG_PAGE_PER_BLOCK)*page_per_block\n",
    "        prev_page = phys_addr % page_per_block\n",
    "        bitmap = block_struct[prev_block][2][prev_page]\n",
    "        # If valid bitmap is True (data is valid), copy to OP capacity, increase GC writes\n",
    "        if (bitmap == True):\n",
    "            invalidate_lba(gc_lba)\n",
    "            #check if we need to get a new block\n",
    "            cur_block = check_GC(cur_block,in_gc)\n",
    "            #move the gc'ed block t-o a new location\n",
    "            map_lba(gc_lba,cur_block)   \n",
    "            gc_writes = gc_writes + 1\n",
    "           \n",
    "            \n",
    "    if(gc_writes > 64):\n",
    "        print(\"GC writes not as expected\", gc_writes)\n",
    "        \n",
    "    # Reset block details, remove from closed list and add to free_list\n",
    "    invalid_pages = 0\n",
    "    valid_bitmap = []\n",
    "    write_ptr = 0\n",
    "    for x in range(page_per_block):\n",
    "        valid_bitmap.append(False)\n",
    "        \n",
    "    block_struct[gc_blk]= [gc_blk,invalid_pages,valid_bitmap,write_ptr]\n",
    "    closed_blocks.remove(gc_blk)\n",
    "    free_list_block.append(gc_blk)\n",
    "    total_gc_writes[0] = total_gc_writes[0] + gc_writes\n",
    "    in_gc = False\n",
    "    return in_gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage completed in (%)  : 18.832338515051276\n",
      "Percentage completed in (%)  : 28.248507772576914\n",
      "Percentage completed in (%)  : 37.66467703010255\n",
      "Percentage completed in (%)  : 47.08084628762819\n",
      "Percentage completed in (%)  : 56.49701554515383\n",
      "Percentage completed in (%)  : 65.91318480267947\n",
      "Percentage completed in (%)  : 75.3293540602051\n",
      "Percentage completed in (%)  : 84.74552331773074\n",
      "Percentage completed in (%)  : 94.16169257525638\n",
      "Trace Replay Ended!\n"
     ]
    }
   ],
   "source": [
    "L2P = {}\n",
    "P2L = {}\n",
    "total_gc_writes = []\n",
    "total_gc_writes.append(0)\n",
    "counter = 0\n",
    "GC_THRESHOLD = 100\n",
    "min_LBA = min(lba_list)\n",
    "closed_blocks = []\n",
    "cur_block = free_list_block.pop(0)\n",
    "block_details = block_struct[cur_block]\n",
    "global in_gc \n",
    "in_gc = False\n",
    "global gc_writes\n",
    "gc_writes = 0\n",
    "total_writes = []\n",
    "total_writes.append(0)\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "while(counter < len(lba_list)):\n",
    "    lba=int(lba_list[counter]) - min_LBA\n",
    "    if(counter >100000 and counter%100000==0):\n",
    "        print(\"Percentage completed in (%)  :\", (counter/len(lba_list))*100)\n",
    "    if lba in L2P:\n",
    "        invalidate_lba(lba)\n",
    "    cur_block = check_GC(cur_block,in_gc)\n",
    "    map_lba(lba,cur_block)\n",
    "    counter = counter + 1\n",
    "    \n",
    "end_time = time.time()\n",
    "run_time = end_time - start_time\n",
    "print(\"Trace Replay Ended!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GC Threshold set 100\n",
      "OverProvisioning Ratio : 0.2\n",
      "Total Number of Writes : 3214074\n",
      "Total Number of user writes : 1062003\n",
      "Total Number of GC writes : 2152071\n",
      "Write Amplification:   3.0264264790212456\n",
      "Execution Time for the FTL : 21.498674869537354\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"GC Threshold set\",GC_THRESHOLD)\n",
    "print(\"OverProvisioning Ratio :\",over_provisioning_ratio)\n",
    "print(\"Total Number of Writes :\",(total_writes[0]))\n",
    "print(\"Total Number of user writes :\",(total_writes[0] - total_gc_writes[0]))\n",
    "print(\"Total Number of GC writes :\",total_gc_writes[0])\n",
    "print(\"Write Amplification:  \",total_writes[0]/(total_writes[0] - total_gc_writes[0]))\n",
    "print(\"Execution Time for the FTL :\",run_time)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
